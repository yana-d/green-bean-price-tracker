{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8611e3a3",
   "metadata": {},
   "source": [
    "# **Green Bean Price Tracker**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927a0e7c",
   "metadata": {},
   "source": [
    "## Passing login form with Requests and BautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8b34df",
   "metadata": {},
   "source": [
    "Imports (it is successful if there are no errors)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e02368",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standart packages\n",
    "import pandas as pd \n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# E-mail notifictions packages\n",
    "import smtplib\n",
    "from email.mime.multipart import MIMEMultipart\n",
    "from email.mime.text import MIMEText\n",
    "\n",
    "# Custom imports\n",
    "import config as cfg "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f4b7cf",
   "metadata": {},
   "source": [
    "__Requests__ is an HTTP library for Python, that allows to send HTTP/1.1 requests easy (no need to manually add query strings to your URLs, or to form-encode your POST data.) Keep-alive and HTTP connection pooling are 100% automatic, thanks to urllib3.\n",
    "\n",
    "__Beautiful Soup__ is a Python library for pulling data out of HTML and XML files (we will work with HTML files), by representing the HTML as a set of objects with methods used to parse the HTML. We can navigate the HTML as a tree and/or filter out what we are looking for.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca735bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URL of our target page we gonna scrap.\n",
    "url = \"https://offerlist.rehmcoffee.de\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "891475b9",
   "metadata": {},
   "source": [
    "__Session__ object because:\n",
    "+ it allows us to persist certain parameters across requests\n",
    "+ it persists cookies across all requests made from the Session instance \n",
    "+ It has all the methods of the main Requests API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bdcc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0702ab5a",
   "metadata": {},
   "source": [
    "Firstly, we use __Requests__ to get access to the page content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c935f01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Requests's method get on session object to get access to the page content.\n",
    "login_form = s.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfbc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing out the URL of the page to check if everything works proper.\n",
    "login_form.url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c30eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling attribute content to see the content of the login page before we try to log in.\n",
    "login_form.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3df1ffdc",
   "metadata": {},
   "source": [
    "To parse a document, we pass it into the `BeautifulSoup` constructor.Then we create a `BeautifulSoup` object : *soup* , which represents the document as a nested data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b33aea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_login_form = BeautifulSoup(login_form.content,\"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18202e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using prettify() method  to display the HTML in the nested structure:\n",
    "print(soup_login_form.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074c64ed",
   "metadata": {},
   "source": [
    "Next, we search for inputs are required to submit to login form to pass it. Below we can see that not _user_ and _password_ but also few extra tokens are required. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae7f294",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list_input = soup_login_form.find_all(\"input\")\n",
    "list_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3f9386",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_nr1 = soup_login_form.find(\"input\", {\"name\":\"logintype\"})[\"value\"]\n",
    "token_nr2 = soup_login_form.find(\"input\", {\"name\":\"pid\"})[\"value\"]\n",
    "token_nr3 = soup_login_form.find(\"input\", {\"name\":\"redirect_url\"})[\"value\"]\n",
    "token_nr4 = soup_login_form.find(\"input\", {\"name\":\"tx_felogin_pi1[noredirect]\"})[\"value\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e306de8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(token_nr1)\n",
    "print(token_nr2)\n",
    "print(token_nr3)\n",
    "print(token_nr4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c92008",
   "metadata": {},
   "source": [
    "Earlier we created __config.py__ to store sensitive data as usernames and passwords. \n",
    "\n",
    "If you try to find register form at https://offerlist.rehmcoffee.de , there is none. You need to contact company and request login info. Be aware you will need to provide company info to get access to offer page. \n",
    "\n",
    "\n",
    "__config.py__ consists of a line of code, a dictionary of the following format:\n",
    "\n",
    "`login_data = {'user': 'name@company-name.com', 'pass': 'password_received_from_trader'}`\n",
    "A config file has to be created in the root directory of the project and it will be called from the code as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5005747",
   "metadata": {},
   "outputs": [],
   "source": [
    "#login_data = {\"user\":\"mymail@company-name.com\", \"pass\":\"your_password\", \"logintype\":token_nr1, \"pid\":token_nr2, \"redirect_url\":token_nr3, \"tx_felogin_pi1[noredirect]\":token_nr4}\n",
    "login_data = cfg.login_data\n",
    "login_data[\"logintype\"] = token_nr1\n",
    "login_data[\"pid\"] = token_nr2\n",
    "login_data[\"redirect_url\"] = token_nr3\n",
    "login_data[\"tx_felogin_pi1[noredirect]\"] = token_nr4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d30dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "s.post(url, login_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0feddae",
   "metadata": {},
   "source": [
    "__Status code:200__ in the Response message in HTTP Protocol stays for OK (any 2xx stays for Success). If we skip `Session()` and go for `requests.get(url)` above, while our response code will be still OK we will not stay logged in what will result in landing on login form again again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42b3698c",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_page = s.get(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd6f6465",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "offer_page.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33c05f15",
   "metadata": {},
   "source": [
    "Going throgh content we see that we successfully passed the login form and have excess to data we going to scrap. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d676de",
   "metadata": {},
   "source": [
    "## Using **BeautifulSoup** and **Pandas** to extract the data into DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74eef60",
   "metadata": {},
   "source": [
    "Pass HTML into the `BeautifulSoup` constructor, then create a new `BeautifulSoup` object : *soup_offer_page* , which represents the HTML code as a nested data structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3215db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "soup_offer_page = BeautifulSoup(offer_page.content,\"html5lib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7671a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(soup_offer_page.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0a0cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking how many tables are on page.\n",
    "\n",
    "tables = soup_offer_page.find_all('table')\n",
    "len(tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d53137c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tables"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c18e80f6",
   "metadata": {},
   "source": [
    "The output is 3 tables. If we visit the  https://offerlist.rehmcoffee.de/ we can see exactly 3 tables: Stock Exchange, Your Contact and the third one in which on fact we are interested in."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b043971",
   "metadata": {},
   "source": [
    "Now we automate table choice. Below the loop that search for words in tables and prints an index of a table in cell below, than displays the html code as nested structure of this table in the next cell. (we need to feed it with words unique to the table we are searching)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b9c250",
   "metadata": {},
   "outputs": [],
   "source": [
    "for index,table in enumerate(tables):\n",
    "    if (\"almond\" in str(table)):\n",
    "        table_index = index\n",
    "        \n",
    "print(table_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d59183",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tables[table_index].prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2462cec8",
   "metadata": {},
   "source": [
    "It is possible to scrape data from HTML tables into a DataFrame using BeautifulSoup and the Pandas function `read_html`that creates a DataFrame and populates it.\n",
    "\n",
    "Our table is `tables[table_index]`. \n",
    "\n",
    "When we use the pandas function `read_html`, we give it the string version of the table as well as the flavor which is the parsing engine bs4.\n",
    "\n",
    "The function `read_html` always returns a list of DataFrames so we must pick the one we want out of the list. We use `[0]` index as we already spicified proper table from tables above.\n",
    "\n",
    "We can also use the read_html function to directly get DataFrames from a url and than pick the DataFrame we need out of the list as follows (but this works when we don't need to pass a login form):\n",
    "<code>\n",
    "whole_page_df = pd.read_html(url, flavor='bs4')\n",
    "len(whole_page_df)\n",
    "whole_page_df[1]\n",
    "<code>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605a7733",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_list_rehm_df = pd.read_html(str(tables[table_index]), flavor='bs4')[0]\n",
    "offer_list_rehm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7399aa1c",
   "metadata": {},
   "source": [
    "## Data preparation before storaging "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c08577",
   "metadata": {},
   "source": [
    "### Adding Date column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02cf07a7",
   "metadata": {},
   "source": [
    "We create Timestamp object that provides current Timestamp, using Pandas `.to_datetime` method on arg 'today' to get current timestamp (not just date) in local timezone and `normalize()` to keep the date as a Timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd76244",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_date = pd.to_datetime('today').normalize()\n",
    "current_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "079f1a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_list_rehm_df['offer_date'] = current_date\n",
    "offer_list_rehm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa4c5133",
   "metadata": {},
   "source": [
    "### Modifying Unit, € / KG and D / KG columns values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c99a0",
   "metadata": {},
   "source": [
    "Copy dataframe to check how our functions acts and modify data only after all functions correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b570069",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_list_rehm_df_copy = offer_list_rehm_df.copy(deep=True)\n",
    "\n",
    "offer_list_rehm_df_copy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e4de353",
   "metadata": {},
   "source": [
    "First we create functions to modify the column's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ffa0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_unit_col(x):\n",
    "    x = x.replace(\"kg\", \"\").replace(\" \", \"\")\n",
    "    return int(x)\n",
    "\n",
    "def clean_eur_col(y):\n",
    "    y = y.replace(\"€\", \"\").replace(\",\", \".\").replace(\" \", \"\")\n",
    "    return round(float(y),2)\n",
    "\n",
    "def clean_usd_col(z):\n",
    "    z = z.replace(\"$\", \"\").replace(\",\", \".\").replace(\" \", \"\")\n",
    "    return round(float(z),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b428027d",
   "metadata": {},
   "source": [
    "Now we pass it to apply method. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a7df42",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_list_rehm_df_copy['Unit'] = offer_list_rehm_df_copy['Unit'].apply(clean_unit_col)\n",
    "\n",
    "offer_list_rehm_df_copy['€ / KG'] = offer_list_rehm_df_copy['€ / KG'].apply(clean_eur_col)\n",
    "\n",
    "offer_list_rehm_df_copy['$ / KG'] = offer_list_rehm_df_copy['$ / KG'].apply(clean_usd_col)\n",
    "\n",
    "offer_list_rehm_df_copy.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c35a9f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: run only first time!\n",
    "offer_list_rehm_df_copy.to_csv('scraped-data/rehm-offer-list.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fb427c1",
   "metadata": {},
   "source": [
    "Now our info bundle is completed. We can move further and place it in file. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7c2202",
   "metadata": {},
   "source": [
    "## Placing scraped data for storage in .csv file using  **Pandas** on local machine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c993f37",
   "metadata": {},
   "source": [
    "Using cell magic we execute `bash` commands to create folders to place our scraped data in a properly arranged manner."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8404b03d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "mkdir green-bean-price-tracker \n",
    "cd green-bean-price-tracker \n",
    "mkdir scraped-data\n",
    "cd ~"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ab5dbd7",
   "metadata": {},
   "source": [
    "Using line magic we check Path Working Directory to be sure that we got back to proper location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef49a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ce55df",
   "metadata": {},
   "source": [
    "Using `to_scv` method we create .csv file where we will collect our data as green bean trader publish new updates to offer list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35fb56a",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_list_rehm_df_copy.to_csv('scraped-data/rehm-offer-list.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bf731d3",
   "metadata": {},
   "source": [
    "Now we can check our folders and the.csv file manually to be sure all in place. If we open .csv file with Excel we can see some formating issues therefore we will check the values calling `read_csv` to be sure all values are intact. If you got Error trying to read file, check whether you closed the fail in Excel after checking it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4c1b60",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.read_csv('scraped-data/rehm-offer-list.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "465f870c",
   "metadata": {},
   "source": [
    "## Reparing .csv fail\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5669b586",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_forteen = pd.read_csv('scraped-data/rehm-offer-list-14.04.2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb2e905e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read_forteen.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5433929",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_twentyone.to_csv('scraped-data/rehm-offer-list-new.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e24992",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read_twentyeight = pd.read_csv('scraped-data/rehm-offer-list-28.04.2021.csv', sep=',' ,  index_col=False)\n",
    "df_read_twentyeight.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc2d13cd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read_the_last = pd.read_csv('scraped-data/rehm-offer-list.csv')\n",
    "df_read_the_last.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c93b72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read_the_last.to_csv('scraped-data/rehm-offer-list-new.csv',mode='a',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12a41f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_read_today = pd.read_csv('scraped-data/rehm-offer-list-new.csv')\n",
    "df_read_today.head(214)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8bbe8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "offer_list_rehm_df_copy.to_csv('scraped-data/rehm-offer-list-new.csv',mode='a',index=False,header=False)\n",
    "#offer_list_rehm.to_csv('scraped-data/rehm-offer-list-new.csv',mode='a',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24faeb60",
   "metadata": {},
   "source": [
    "## Appending .csv fail with new data release"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b701c7f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b5022f2e",
   "metadata": {},
   "source": [
    "The green bean trader publishes updates to the offer list weekly. We plan to log in weekly and append the .csv fail with full list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0940167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTANT: run only when new data is available from trader!\n",
    "offer_list_rehm.to_csv('scraped-data/rehm-offer-list.csv',mode='a',index=False,header=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b949f42e",
   "metadata": {},
   "source": [
    "Checking whether new data is available from trader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2072421",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_today = pd.read_csv('scraped-data/rehm-offer-list.csv')\n",
    "df_previous = pd.read_csv('scraped-data/rehm-offer-list-14.04.2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51627d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous.Bags == offer_list_rehm.Bags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b82e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_previous.Bags.compare(offer_list_rehm.Bags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f7ea0aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fe7a320a",
   "metadata": {},
   "source": [
    "## Compare dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ee928c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_last = pd.read_csv('scraped-data/rehm-offer-list.csv', index_col = False)\n",
    "#df_last = df_last.reset_index(drop=True)\n",
    "df_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00df4078",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twentyone = pd.read_csv('scraped-data/rehm-offer-list-21.04.2021.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc984d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twentyone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9778889",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twentyone.set_index(['Farm / Name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f53017",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_twentyone.set_index(['Farm / Name']).sort_index(ascending=True).loc['Burka Estate AB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb24c732",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last.compare(df_twentyone, keep_shape=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "582cf5f6",
   "metadata": {},
   "source": [
    "## Data Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb0db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_read = pd.read_csv('scraped-data/rehm-offer-list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01e9e650",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_likelast = df_read.loc[df_read['offer_date'] == current_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3401bb9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_likelast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee22bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140d40ce",
   "metadata": {},
   "source": [
    "For the \"Bags\" provide a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba2ce2d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x='Bags', data = df_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c52dd1b",
   "metadata": {},
   "source": [
    "Create a histogram for the \"Bags\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e64cd3",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ax = sns.displot(df_last['Bags'], kde = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d0b44f6",
   "metadata": {},
   "source": [
    "For the \"€ / KG\" provide a boxplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74d18022",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.boxplot(x='€ / KG', data = df_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4bbd7f",
   "metadata": {},
   "source": [
    "Provide a boxplot for the \"€ / KG\" variable vs the \"Bags\" variable. (Discretize the \"€ / KG\" variable into three groups of 4 € / KG and less, between 4 and 8 € / KG and 8 € / KG and higher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa559b0b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_last.loc[(df_last['€ / KG'] <= 4), 'price_group'] = '4 EUR and less'\n",
    "df_last.loc[(df_last['€ / KG'] > 4)&(df_last['€ / KG'] < 8), 'price_group'] = 'between 4 and 8 EUR'\n",
    "df_last.loc[(df_last['€ / KG'] >= 8), 'price_group'] = '8 EUR and up'\n",
    "\n",
    "ax = sns.boxplot(x=\"price_group\", y=\"Bags\", data=df_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0236ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=\"total_KG_per_coffee\",hue=\"price_group\",multiple=\"stack\",data=df_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cceff14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(x=\"total_KG_per_coffee\",hue=\"Origin\", kind='kde',data=df_last)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea32c9a7",
   "metadata": {},
   "source": [
    "Provide a scatter plot to show the relationship between \"€ / KG\" and the \"Bags\" per coffee. What is up with the relationship?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05636458",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ax = sns.scatterplot(x='€ / KG', y='Bags',  data=df_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a34d502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last['total_KG_per_coffee'] = df_last['Bags'] * df_last['Unit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc484d6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last['total_EUR_per_coffee'] = df_last['total_KG_per_coffee'] * df_last['€ / KG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c2876c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_last.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8d128",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.histplot(df_last[df_last['Origin'] == 'BRAZIL']['total_KG_per_coffee'], color='green', kde=False) \n",
    "sns.histplot(df_last[df_last['Origin'] == 'PANAMA']['total_KG_per_coffee'], color=\"blue\", kde=False) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2228e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_summary = df_last.groupby('Origin')['total_EUR_per_coffee'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3898e1f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(country_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd4f4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699fe6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_summary.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd72f40",
   "metadata": {},
   "source": [
    "## E-mail notifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096a1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "email_body = \"<html><body>Hey folks! That's green-bean-price-tracker bot here. I've prepared some fresh tasty updates to coffee offers by Rehm from: \"\n",
    "\n",
    "email_body += str(current_date)\n",
    "\n",
    "email_body += '<br>actual info will be inserted here'\n",
    "\n",
    "email_body += '<br>Yours green-bean-price-tracker bot</body></html>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee86e18c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Email Account\n",
    "email_sender_account = cfg.email_sender_account # email_sender_account = \"your.registered.name@gmail.com\"\n",
    "email_sender_username = cfg.email_sender_username # email_sender_username = \"your.registered.name\"\n",
    "email_sender_password = cfg.email_sender_password # email_sender_password = \"your_gmail_password\"\n",
    "email_smtp_server = \"smtp.gmail.com\" # SMTP, eg smtp.gmail.com for gmail\n",
    "email_smtp_port = 587 # SMTP Porf, eg 587 for gmail\n",
    "\n",
    "# Email Content\n",
    "email_recepients = [\"yana.dzhulay@dbf-regensburg.de\",\"mail@dbf-regensburg.de\"]\n",
    "email_subject = \"test notification - weekly updates - green-bean-price-tracker \"\n",
    "#email_body = \"here is the body\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b3b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# login to email server\n",
    "server = smtplib.SMTP(email_smtp_server,email_smtp_port)\n",
    "server.starttls()\n",
    "server.login(email_sender_username, email_sender_password)\n",
    "\n",
    "# For loop, sending emails to all email recipients\n",
    "for recipient in email_recepients:\n",
    "    print(\"Sending email to: \" , recipient)\n",
    "    message = MIMEMultipart('alternative')\n",
    "    message['From'] = email_sender_account\n",
    "    message['To'] = recipient\n",
    "    message['Subject'] = email_subject\n",
    "    message.attach(MIMEText(email_body, 'html'))\n",
    "    text = message.as_string()\n",
    "    server.sendmail(email_sender_account,recipient,text)\n",
    "    \n",
    "# All emails sent, log out.\n",
    "server.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2c526c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
